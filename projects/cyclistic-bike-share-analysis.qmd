---
title: The Cyclistic Bike-share Analysis Case Study
author: "Albert Joonyoung Park"
description: "Data analysis and recommendations for the bike-share company Cyclistic, to navigate speedy success."
date: "February 5, 2023"
image: "green-bike-share.jpg"
format:
  html:
    toc: true
    toc-title: Table of Contents
    toc-expand: 2
    title-block-categories: false
    categories: true
    fields: [Data Analysis, Case Study, R, Data Visualization]
---

------------------------------------------------------------------------

::: {style="text-align: center; font-size: x-large;"}
Case Study 1
:::

# How Does a Bike-Share Navigate Speedy Success?

![](/images/cyclistic-bikeshare.png){width="182"}

### Introduction

This document has been produced as a case study capstone project for Google Data Analytics Professional Certificate.In this case study, I performed many real-world tasks of a junior data analyst. I work for a fictional company, Cyclistic, and meet different characters and team members. In order to answer the key business questions, the project followed the steps of the data analysis process: **ask**, **prepare**, **process**, **analyze**, **share**, and **act**.

### Scenario

Cyclistic is a fictional bike-share company based in Chicago, dedicated to optimizing its future success by maximizing the number of annual memberships. As the director of marketing, you recognize the importance of understanding the distinct usage patterns between casual riders and annual members in order to develop an effective marketing strategy. The goal is to convert casual riders into loyal annual members, ultimately driving the company's growth.

### Characters and teams

-   **Cyclistic**: A bike-share program that features more than 5,800 bicycles and 600 docking stations. Cyclistic sets itself apart by also offering reclining bikes, hand tricycles, and cargo bikes, making bike-share more inclusive to people with disabilities and riders who can't use a standard two-wheeled bike. The majority of riders opt for traditional bikes; about 8% of riders use the assistive options. Cyclistic users are more likely to ride for leisure, but about 30% use them to commute to work each day.

-   **Lily Moreno**: The director of marketing and your manager. Moreno is responsible for the development of campaigns and initiatives to promote the bike-share program. These may include email, social media, and other channels.

-   **Cyclistic marketing analytics team**: A team of data analysts who are responsible for collecting, analyzing, and reporting data that helps guide Cyclistic marketing strategy. You joined this team six months ago and have been busy learning about Cyclistic's mission and business goals --- as well as how you, as a junior data analyst, can help Cyclistic achieve them.

-   **Cyclistic executive team**: The notoriously detail-oriented executive team will decide whether to approve the recommended marketing program.

### About the company

In 2016, Cyclistic launched a successful bike-share offering. Since then, the program has grown to a fleet of 5,824 bicycles that are geotracked and locked into a network of 692 stations across Chicago. The bikes can be unlocked from one station and returned to any other station in the system anytime.

Until now, Cyclistic's marketing strategy relied on building general awareness and appealing to broad consumer segments. One approach that helped make these things possible was the flexibility of its pricing plans: single-ride passes, full-day passes, and annual memberships. Customers who purchase single-ride or full-day passes are referred to as casual riders. Customers who purchase annual memberships are Cyclistic members.

Cyclistic's finance analysts have concluded that annual members are much more profitable than casual riders. Although the pricing flexibility helps Cyclistic attract more customers, Moreno believes that maximizing the number of annual members will be key to future growth. Rather than creating a marketing campaign that targets all-new customers, Moreno believes there is a very good chance to convert casual riders into members. She notes that casual riders are already aware of the Cyclistic program and have chosen Cyclistic for their mobility needs.

Moreno has set a clear goal: Design marketing strategies aimed at converting casual riders into annual members. In order to do that, however, the marketing analyst team needs to better understand how annual members and casual riders differ, why casual riders would buy a membership, and how digital media could affect their marketing tactics. Moreno and her team are interested in analyzing the Cyclistic historical bike trip data to identify trends.

### Project deliverables

Produce a report with the following deliverables:

> 1.  A clear statement of the business task.
> 2.  A description of all data sources used.
> 3.  Documentation of any cleaning or manipulation of data.
> 4.  A summary of your analysis.
> 5.  Supporting visualizations and key findings.
> 6.  Your top three recommendations based on your analysis.

### Ask

**Key tasks:**

**1. Identify the business task**

  The business objective is to convert occasional riders into annual members, which is crucial for driving   the company's future growth. The primary purpose of this analysis is to identify trends and differences   in riding behavior between casual riders and annual members. The insights derived from this analysis   will serve as a foundation for informing the company's marketing strategies and efforts aimed at   converting casual riders into loyal annual members.

**2. Key stakeholders:**

  Cyclistic executive team, Director of Marketing (Lily Moreno), Marketing Analytics team

[**Statement of the business task**]{.deliverables style="background-color: yellow;"}

Understand how Cyclistic casual riders and annual members ride differ by analyzing the Cyclistic historical bike trip data to identify trends.

### Prepare

**Key tasks:**

**1. Download data and store it appropriately.**

The previous 12 months of Cyclistic trip data is available for download [here](https://divvy-tripdata.s3.amazonaws.com/index.html). They are made available by Motivate International Inc., under [license](https://ride.divvybikes.com/data-license-agreement). 12 CSV files have been downloaded and saved in the folder C:\\Users\\Joon\\git\\albert-joonyoung-park.github.io\\data.

**2. Identify how it's organized**

The data files are in csv format, and organized into individual month for the past 12 month period.

**3. Sort and filter the data.**

Spreadsheet was used to perform for initial inspection on some data files, and found some issues that require data cleaning and transformation.

-   Manyu columns contain some missing values - started_at, ended_at, start_station_name, end_station_name, end_station_id, start_lat, end_lat

-   ride_id column contains inconsistent data types, mixture of character and number type data.

-   When "ride length was calculated based on" based on started_at, ended_at, some results showed unrealistic large or small numbers, exceeding over 24 hour, 0 or a few minutes of trips.

-   All files have the same column names and same number of columns.

-   Each data file contains large amount of rows ranging 180,000 - 800,000+ rows.

**4. Determine the credibility of the data.**

**ROCCC** measurement was applied to check the credibility of the data.

-   **R**eliable (R): The collection of dataset provide the full 12-month bike trip data. It is partial or biased.

-   **O**riginal (O): The dataset is first party and public data, directly supplied by the the company - Cyclistic.

-   **C**omprehensive (C): The dataset contains enough information to answer the business task in question.

-   **C**urrent (C): The dataset is current, proviing the current full-year bike trip data.

-   **C**ited (C): The dataset is made available as public data by the company and municipality, and is clearly cited online with license information.

[**A description of all data sources used**]{.deliverables}

12 bike trip csv data files for the period from May 2022 to April 2023 were used as data source. The data source was available as first party public data by the company Motivate International Inc. The original files are named below.

| File name                       |
|---------------------------------|
| 202205-divvy-tripdata.csv       |
| 202206-divvy-tripdata.csv       |
| 202207-divvy-tripdata.csv       |
| 202208-divvy-tripdata.csv       |
| 202209-divvy-publictripdata.csv |
| 202210-divvy-tripdata.csv       |
| 202211-divvy-tripdata.csv       |
| 202212-divvy-tripdata.csv       |
| 202301-divvy-tripdata.csv       |
| 202302-divvy-tripdata.csv       |
| 202303-divvy-tripdata.csv       |
| 202304-divvy-tripdata.csv       |

### Process

**Key tasks**

1\. Check the data for errors.

2\. Choose your tools.

3\. Transform the data so you can work with it effectively.

4\. Document the cleaning process.

[**Deliverable**]{.delivarable}

R was chosen for data inspection, cleaning and manipulation. The following code blocks are steps of data cleaning and manipulations for future analysis.

```{r Load libraries, echo=TRUE, message=FALSE, warning=FALSE}

# Set up working directory
setwd("C:/Users/Joon/git/albert-joonyoung-park.github.io/projects")

# Load required libraries to use
library(tidyverse)
library(dplyr)
library(lubridate)
library(skimr)
library(ggplot2)
library(knitr)
library(scales)
library(leaflet)
library(kableExtra)

```

```{r Clean dataset, echo=TRUE, message=FALSE, warning=FALSE}

# List all the CSV data file names to be imported.
file_names <- list.files(path = "../data/",
                         pattern = "*.csv", full.names = FALSE,
                         recursive = FALSE)
# file_names

# Import csv data files one at time and clean, transform the data
total_num_rows <- 0
total_num_rows_dropped <- 0
total_num_rows_duplicated <- 0

for (name in file_names) {
  
  # Import a csv file
  data <- read_csv(paste("../data/", name, sep = ""))
  num_rows <- nrow(data)
  #print(paste(num_rows, "rows imported from", name)) # number of rows imported
  total_num_rows <- total_num_rows + num_rows
  
  # Cleaning - drop rows with missing values - NA
  data_na_dropped <- drop_na(data)
  num_rows_dropped <- num_rows - nrow(data_na_dropped)
  #print(paste(num_rows_dropped,"rows with missing value dropped from",name))
  total_num_rows_dropped <- total_num_rows_dropped + num_rows_dropped
  
  # Cleaning - remove duplicates
  data_unique_na_dropped <- distinct(data_na_dropped)
  num_rows_duplicated <- nrow(data_unique_na_dropped) - nrow(data_na_dropped)
  total_num_rows_duplicated <- total_num_rows_duplicated + num_rows_duplicated
  
  # Transformation:
  # add columns to increase aggregation levels for analysis.
  # lmit ride_length values
  trip_month_data_clean <- 
    data_unique_na_dropped |> 
      mutate(
        start_date = as.Date(started_at),
        start_hour = format(started_at, "%H"),
        start_month = format(start_date, "%m"),
        start_day = format(start_date, "%d"),
        start_year = format(start_date, "%Y"),
        #start_weekday = format(start_date, "%A"),
        start_weekday = wday(start_date, week_start = 7),
        ride_length = difftime(ended_at, started_at, units = "secs"),
        .after = started_at
      ) |> 
      filter(ride_length > 0 & ride_length <= 3600) # limit ride_length

  # Save cleaned data files as a CSV file
  write_csv(trip_month_data_clean, 
            paste("../data/cleaned_datasets/", name, sep = ""))
}

# print some row number changes and structure of cleaned data being saved
total_num_rows # 5859061 rows
total_num_rows_dropped # 1325062 rows
total_num_rows_duplicated # 0 row
glimpse(trip_month_data_clean)

```

### Analyze

**Key tasks**

1\. Aggregate your data so it's useful and accessible.

2\. Organize and format your data.

3\. Perform calculations.

4\. Identify trends and relationships.

**Deliverable**

A summary of your analysis

```{r Aggregate and format cleaned dataset, echo=TRUE, message=FALSE, warning=FALSE}
#----------------------------------------------------------------------------
# Aggregate the cleaned dataset into a single data frame and inspect further
#----------------------------------------------------------------------------

# Get all the cleaned data file names for aggregation
file_names <- list.files(path = "../data/cleaned_datasets/",
                         pattern = "*.csv", full.names = FALSE,
                         recursive = FALSE)

# Import the first monthly cleaned csv file, so it constructs the data frame
# for full year aggregation
full_year_trips <- read_csv(paste("../data/cleaned_datasets/", file_names[1], sep = ""))

# Aggregate the remainig csv files, starting from the second
for(name in file_names[2:length(file_names)]) {
  # Read csv file
  trip_month_data_clean <- read_csv(paste("../data/cleaned_datasets/", 
                                          name, sep = ""))
  
  # Aggregate the monthly data
  full_year_trips <- rbind(full_year_trips, trip_month_data_clean)
  
  # Drop duplicates
  full_year_trips <- drop_na(full_year_trips)
  
  # Save monthly trip data into a aggregated csv file
  write_csv(trip_month_data_clean, "../data/analyzed_datasets/full_year_trips.csv",
            append = TRUE)
}

# Check the overview of the aggregated dataset
# skim(full_year_trips) # 4393697

```

```{r Analysis, echo=TRUE, message=FALSE, warning=FALSE}
#----------------------------------------------------------------------------
# Analyze the aggregated data and create summary to find trends
# Use quesstion, data summary, visualization format
# Save each summary
#----------------------------------------------------------------------------

# !. Basic descriptive ananlysis on ride length per member and casual groups.

ride_length_membership <- 
full_year_trips |> 
  group_by(membership = member_casual) |> 
  summarize(
    mean = round(mean(ride_length / 60)),
    median = round(median(ride_length / 60)),
    max = round(max(ride_length / 60)),
    min = round(min(ride_length / 60))
  )

p <- 
ride_length_membership |> 
    pivot_longer(cols = c(mean, median, max, min),
               names_to = "statistic",
               values_to = "ride_length") |> 
    ggplot(aes(x = statistic, y = ride_length, fill = membership)) + 
    geom_col(position = "dodge2") +
    geom_label(
      aes(label = ride_length),
      size = 4,
      color = "white",
      position = position_dodge(width = 0.9), vjust = 0.2
    ) +
    labs(title = "Ride length stats. by membership", size = 14) +
    labs(x = "Basic statistic", y = "Ride length (mins.)", fill = "Membership") 

p <- p + ylim(min(ride_length_membership$min), max(ride_length_membership$max) + 10)


# Save the summary data
write_csv(ride_length_membership, 
          "../data/analyzed_datasets/ride_length_membership.csv")

# Save the plot
plot_name <- deparse(substitute(ride_length_membership))
ggsave(paste("../data/analyzed_datasets/", plot_name, ".png"), p, width = 6, height = 4, dpi = 300)
p
```

```{r Average weekday ride length, echo=TRUE, message=FALSE, warning=FALSE}
# 2. Average ride length of day of week per casual and member group
ride_length_weekday_avg <- 
  full_year_trips |> 
    group_by(start_weekday, member_casual) |> 
    summarize(avg_ride_length = round(mean(ride_length) / 60)) |> 
    arrange(start_weekday) |>
    mutate(start_weekday = recode(start_weekday, 
                                  "1" = "Sunday", 
                                  "2" = "Monday", 
                                  "3" = "Tuesday", 
                                  "4" = "Wednesday", 
                                  "5" = "Thursday", 
                                  "6" = "Friday", 
                                  "7" = "Saturday"))
ride_length_weekday_avg

p <- 
ride_length_weekday_avg |> 
ggplot() +
  geom_col(
    aes(x = factor(start_weekday, levels=c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")), 
        y = avg_ride_length, 
        fill = member_casual),
    position = "dodge"
  ) +
  labs(title = "Average ride length by weekday", size = 14) +
  labs(x = "Weekday", y = "Ride length (mins.)", fill = "Membership")


# Save the summary data
write_csv(ride_length_weekday_avg, 
          "../data/analyzed_datasets/ride_length_weekday_avg.csv")

# Save the plot
plot_name <- deparse(substitute(ride_length_weekday_avg))
ggsave(paste("../data/analyzed_datasets/", plot_name, ".png"), p, width = 6, height = 4, dpi = 300)
p
```

```{r Ride frequency weekday, echo=TRUE, message=FALSE, warning=FALSE}
# 3. Ride count for day of week per member vs casual group.

ride_count_weekday <- 
  full_year_trips |> 
    mutate(weekday = wday(started_at, label = TRUE)) |> 
    group_by(member_casual, weekday) |> 
    summarise(
      number_of_rides = n(),
      avg_ride_length = as.integer(mean(ride_length)/60)
    ) |> 
    arrange(member_casual, weekday)

ride_count_weekday

# Visualize the number of rides by rider type

p <- 
ride_count_weekday |> 
  ggplot(aes(x = weekday, y = number_of_rides, fill = member_casual)) +
    geom_col(position = "dodge") +
    labs(title = "Ridership by User Type", size = 14) +
    labs(x = "Weekday", y = "Number of rides", fill = "User type") +
    scale_y_continuous(labels = comma)

# Save the summary data
write_csv(ride_count_weekday, 
          "../data/analyzed_datasets/ride_count_weekday.csv")

# Save the plot
plot_name <- deparse(substitute(ride_count_weekday))
ggsave(paste("../data/analyzed_datasets/", plot_name, ".png"), p, width = 6, height = 4, dpi = 300)
p
```

```{r Rideable type frequency, echo=TRUE, message=FALSE, warning=FALSE}
# 4. Rideable type frequencies for day of week per member vs casual group.

dfs_rideable_type_member_casual <- 
  full_year_trips |> 
    group_by(member_casual, rideable_type) |> 
    summarize(ride_count = n()) |> 
    arrange(rideable_type, member_casual, ride_count)

dfs_rideable_type_member_casual

p <- 
dfs_rideable_type_member_casual |> 
  ggplot(aes(x = rideable_type, y = ride_count, fill = member_casual )) +
    geom_bar(stat = "identity") +
    geom_text(
      aes(label = comma(ride_count)),
      size = 3.5,
      position = position_stack(vjust = 0.5),
      colour = "white"
    ) +
    scale_y_continuous(labels = comma) +
    labs(title = "Ride frequency by rideable type", size = 16) +
    labs(subtitle = "Period: 12 months (May 2022 - April 2023)") +
    labs(x = "Rideable type", y = "Frequency", fill = "Membership")

# Save the summary data
write_csv(dfs_rideable_type_member_casual, 
          "../data/analyzed_datasets/dfs_rideable_type_member_casual.csv")

# Save the plot
plot_name <- deparse(substitute(ride_count_weekday))
ggsave(paste("../data/analyzed_datasets/", plot_name, ".png"), p, width = 6, height = 4, dpi = 300)
p
```

```{r Station map both, echo=TRUE, message=FALSE, warning=FALSE}
# 5. Display a map marking the start staion that are frequently used by member or casual riders.

# Geographical mapping of ridership by membership, using leaflet
# Prepare data in a smaller set for plotting - limit to ride frequency over 1200

dfs_ride_start_loc <- 
  full_year_trips |> 
    select(start_station_name, start_lat, start_lng, member_casual) |> 
    group_by(start_station_name, start_lat, start_lng, member_casual) |> 
    summarize(
      ride_frequency = n()
      ) |> 
    filter(ride_frequency >= 1200) # limit the ride_frequency >= 1200

dfs_ride_start_loc

# Create a leaflet map centered on Chicago with map view
# Display both member and casual ridership information

leaflet(options = leafletOptions(zoomControl = TRUE)) |> 
  setView(lng = -87.6298, lat = 41.8781, zoom = 13) |> 
  addTiles() |> 
   addCircleMarkers(
     data = dfs_ride_start_loc,
     lat = ~start_lat,
     lng = ~start_lng,
     radius = ~10,
     color = ~ifelse(member_casual == "member", "blue", "red"),
     popup = ~paste(start_station_name, " | ", member_casual, " | ", ride_frequency),
     stroke = FALSE,
     fillOpacity = 0.0001 * dfs_ride_start_loc$ride_frequency
  )  
```

```{r Station map casual, echo=TRUE, message=FALSE, warning=FALSE}
# Create a leaflet map centered on Chicago with map view
# Display Casual riders information only

dfs_ride_start_loc_casual <- 
  dfs_ride_start_loc |> 
    filter(member_casual == "casual")

leaflet(options = leafletOptions(zoomControl = TRUE)) |> 
  setView(lng = -87.6298, lat = 41.8781, zoom = 13) |> 
  addTiles() |> 
   addCircleMarkers(
     data = dfs_ride_start_loc_casual,
     lat = ~start_lat,
     lng = ~start_lng,
     radius = ~10,
     color = ~"red",
     popup = ~paste(start_station_name, " | ", member_casual, " | ", ride_frequency),
     stroke = FALSE,
     fillOpacity = 0.0001 * dfs_ride_start_loc$ride_frequency
  )  
```

```{r Station map Member, echo=TRUE, message=FALSE, warning=FALSE}
# Create a leaflet map centered on Chicago with map view
# Display Member ridership information only

dfs_ride_start_loc_member <- 
  dfs_ride_start_loc |> 
    filter(member_casual == "member")

leaflet(options = leafletOptions(zoomControl = TRUE)) |> 
  setView(lng = -87.6298, lat = 41.8781, zoom = 13) |> 
  addTiles() |> 
   addCircleMarkers(
     data = dfs_ride_start_loc_member,
     lat = ~start_lat,
     lng = ~start_lng,
     radius = ~10,
     color = ~"blue",
     popup = ~paste(start_station_name, " | ", member_casual, " | ", ride_frequency),
     stroke = FALSE,
     fillOpacity = 0.0001 * dfs_ride_start_loc$ride_frequency
  )  
```

```{r Top20 stations, echo=TRUE, message=FALSE, warning=FALSE}
# 6. What stations are most frequently used by casual riders in the past 12 months?

# Retrieve frequent station information used by casual riders in the past 12 months
dfs_ride_start_loc_casual <- 
  full_year_trips |> 
    filter(member_casual == "casual") |> 
    group_by(start_station_id, start_station_name, member_casual) |> 
    summarize(
      ride_frequency = n(),
      .groups = "drop" # need to set "drop" option to assign ranking properly later
      )

dfs_ride_start_loc_casual <- 
  dfs_ride_start_loc_casual |> 
    arrange(desc(ride_frequency)) |> 
    mutate(rank = rank(-ride_frequency, ties.method = 'min')) |> 
    select(rank, start_station_id, start_station_name, ride_frequency)

dfs_ride_start_loc_casual_ranked <- 
  dfs_ride_start_loc_casual |> 
    rename(
      "rank" = "rank", 
      "station_id" = "start_station_id",
      "station_name" = "start_station_name",
      "ride_count" = "ride_frequency"
    )

# List top 20 stations

dfs_ride_start_loc_casual_ranked_20 <- dfs_ride_start_loc_casual_ranked[1:20,]

# Set ordering
dfs_ride_start_loc_casual_ranked_20$station_name <- factor(dfs_ride_start_loc_casual_ranked_20$station_name, levels = dfs_ride_start_loc_casual_ranked_20$station_name[order(dfs_ride_start_loc_casual_ranked_20$rank, decreasing = TRUE)])

p <- 
dfs_ride_start_loc_casual_ranked_20 |> 
  ggplot(aes(x = ride_count, y = station_name)) +
    geom_bar(stat = "identity") +
    labs(title = "Top 20 stations by CASUAL riders", size = 14) +
    labs(x = "Ride frequency", y = "Station name") +
    scale_x_continuous(labels = comma)

# Save the summary data
write_csv(dfs_ride_start_loc_casual_ranked_20, 
          "../data/analyzed_datasets/dfs_ride_start_loc_casual_ranked_20.csv")

# Save the plot
plot_name <- deparse(substitute(dfs_ride_start_loc_casual_ranked_20))
ggsave(paste("../data/analyzed_datasets/", plot_name, ".png"), p, width = 6, height = 4, dpi = 300)
p

```

```{r Top20 stations table, echo=TRUE, message=FALSE, warning=FALSE}
# Create a styled table with proper number format

dfs_ride_start_loc_casual_ranked_20$ride_count <- format(dfs_ride_start_loc_casual_ranked_20$ride_count, big.mark = ",")

styled_table <- 
  kable(dfs_ride_start_loc_casual_ranked_20, format = "html", align = "c")  |> 
  kable_styling(bootstrap_options = c("striped", "hover"))


styled_table
```

### Share

### Act
