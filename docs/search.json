[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Albert Joon Park",
    "section": "",
    "text": "Albert Joonyoung Park is an aspiring and dedicated independent data analyst with a diverse background spanning entrepreneurship, eCommerce, manufacturing operations, and database application development. With a strong focus on delivering valuable insights, he collaborates closely with clients to extract meaningful information from diverse datasets across various industries. Additionally, Albert has recently ventured into mortgage brokering, aiming to leverage his data skills to assist individuals in identifying optimal financial solutions tailored to their specific needs. Beyond his professional pursuits, Albert finds joy in spending quality time with his spouse, continuously expanding his expertise in data science, actively participating in the church choir, and honing his piano-playing skills."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog Posts",
    "section": "",
    "text": "A Test Blog Post\n\n\nThe first blog post using Quarto.\n\n\n\n\n\n\nJune 1, 2022\n\n\n3 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Greetings from Albert Park",
    "section": "",
    "text": "Welcome to my personal website, where I share my selected examples and blogs on data analysis. The primary aim is to share my enriching journey in data analysis and its multitude of benefits. When data is harnessed and interpreted effectively, it has the remarkable ability to reveal concealed paths that guide decision-making, be it in our personal lives or the business world. To fully unlock its potential, I invite you to don your\"Curiosity Hat\" and explore the stories that lie within the data. Brace yourself, for the results have the potential to transcend mere significance—they possess the inherent power to shape and transform.\n  \n  \n  \n    Albert Joonyoung Park"
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "Albert Joonyoung. Park",
    "section": "",
    "text": "“This is a website created by Albert Joonyoung Park, featuring his personal data analysis examples and blogs. The purpose of the website is to share the benfits of how the raw data can be consumed to produce meaningful insights to help guide things in business and personal life.”"
  },
  {
    "objectID": "posts/my-first-blog.html",
    "href": "posts/my-first-blog.html",
    "title": "A Test Blog Post",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nThis is inline code plus a small code chunk.\n\nlibrary(tidyverse)\n\nggplot(mpg) +\n  geom_jitter(aes(cty, hwy), size = 4, alpha = 0.5) \n\n\n\n\n\n\n\n\nTransforming OLS estimatesMaximizing likelihood\n\n\n\n\nCode\npreds_lm %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\nCode\nglm.mod &lt;- glm(sex ~ body_mass_g + bill_length_mm + species, family = binomial, data = dat)\n\npreds &lt;- dat %&gt;% \n  mutate(\n    prob.fit = glm.mod$fitted.values,\n    prediction = if_else(prob.fit &gt; 0.5, 'male', 'female'),\n    correct = if_else(sex == prediction, 'correct', 'incorrect')\n  )\n\n\npreds %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\\[\n\\int_0^1 f(x) \\ dx\n\\]\n\n\n\n\n\n\n\n\ngeom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\n\n\nstat_density(\n  mapping = NULL,\n  data = NULL,\n  geom = \"area\",\n  position = \"stack\",\n  ...,\n  bw = \"nrd0\",\n  adjust = 1,\n  kernel = \"gaussian\",\n  n = 512,\n  trim = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\n\n\n\n\n\n\n\nggplot(data = gapminder::gapminder, mapping = aes(x = lifeExp, fill = continent)) +\n  stat_density(position = \"identity\", alpha = 0.5)\n\n\n\n\nBla bla bla. This is a caption in the margin. Super cool isn’t it?"
  },
  {
    "objectID": "posts/my-first-blog.html#merriweather",
    "href": "posts/my-first-blog.html#merriweather",
    "title": "A Test Blog Post",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nThis is inline code plus a small code chunk.\n\nlibrary(tidyverse)\n\nggplot(mpg) +\n  geom_jitter(aes(cty, hwy), size = 4, alpha = 0.5) \n\n\n\n\n\n\n\n\nTransforming OLS estimatesMaximizing likelihood\n\n\n\n\nCode\npreds_lm %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\nCode\nglm.mod &lt;- glm(sex ~ body_mass_g + bill_length_mm + species, family = binomial, data = dat)\n\npreds &lt;- dat %&gt;% \n  mutate(\n    prob.fit = glm.mod$fitted.values,\n    prediction = if_else(prob.fit &gt; 0.5, 'male', 'female'),\n    correct = if_else(sex == prediction, 'correct', 'incorrect')\n  )\n\n\npreds %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\\[\n\\int_0^1 f(x) \\ dx\n\\]"
  },
  {
    "objectID": "posts/my-first-blog.html#columns",
    "href": "posts/my-first-blog.html#columns",
    "title": "A Test Blog Post",
    "section": "",
    "text": "geom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\n\n\nstat_density(\n  mapping = NULL,\n  data = NULL,\n  geom = \"area\",\n  position = \"stack\",\n  ...,\n  bw = \"nrd0\",\n  adjust = 1,\n  kernel = \"gaussian\",\n  n = 512,\n  trim = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)"
  },
  {
    "objectID": "posts/my-first-blog.html#margin-captions",
    "href": "posts/my-first-blog.html#margin-captions",
    "title": "A Test Blog Post",
    "section": "",
    "text": "ggplot(data = gapminder::gapminder, mapping = aes(x = lifeExp, fill = continent)) +\n  stat_density(position = \"identity\", alpha = 0.5)\n\n\n\n\nBla bla bla. This is a caption in the margin. Super cool isn’t it?"
  },
  {
    "objectID": "projects/cyclistic-bike-share-analysis.html",
    "href": "projects/cyclistic-bike-share-analysis.html",
    "title": "The Cyclistic Bike-share Analysis Case Study",
    "section": "",
    "text": "Case Study 1\n\n\nHow Does a Bike-Share Navigate Speedy Success?\n\n\nIntroduction\nThis document has been produced as a case study capstone project for Google Data Analytics Professional Certificate.In this case study, I performed many real-world tasks of a junior data analyst. I work for a fictional company, Cyclistic, and meet different characters and team members. In order to answer the key business questions, the project followed the steps of the data analysis process: ask, prepare, process, analyze, share, and act.\n\n\nScenario\nCyclistic is a fictional bike-share company based in Chicago, dedicated to optimizing its future success by maximizing the number of annual memberships. As the director of marketing, you recognize the importance of understanding the distinct usage patterns between casual riders and annual members in order to develop an effective marketing strategy. The goal is to convert casual riders into loyal annual members, ultimately driving the company’s growth.\n\n\nCharacters and teams\n\nCyclistic: A bike-share program that features more than 5,800 bicycles and 600 docking stations. Cyclistic sets itself apart by also offering reclining bikes, hand tricycles, and cargo bikes, making bike-share more inclusive to people with disabilities and riders who can’t use a standard two-wheeled bike. The majority of riders opt for traditional bikes; about 8% of riders use the assistive options. Cyclistic users are more likely to ride for leisure, but about 30% use them to commute to work each day.\nLily Moreno: The director of marketing and your manager. Moreno is responsible for the development of campaigns and initiatives to promote the bike-share program. These may include email, social media, and other channels.\nCyclistic marketing analytics team: A team of data analysts who are responsible for collecting, analyzing, and reporting data that helps guide Cyclistic marketing strategy. You joined this team six months ago and have been busy learning about Cyclistic’s mission and business goals — as well as how you, as a junior data analyst, can help Cyclistic achieve them.\nCyclistic executive team: The notoriously detail-oriented executive team will decide whether to approve the recommended marketing program.\n\n\n\nAbout the company\nIn 2016, Cyclistic launched a successful bike-share offering. Since then, the program has grown to a fleet of 5,824 bicycles that are geotracked and locked into a network of 692 stations across Chicago. The bikes can be unlocked from one station and returned to any other station in the system anytime.\nUntil now, Cyclistic’s marketing strategy relied on building general awareness and appealing to broad consumer segments. One approach that helped make these things possible was the flexibility of its pricing plans: single-ride passes, full-day passes, and annual memberships. Customers who purchase single-ride or full-day passes are referred to as casual riders. Customers who purchase annual memberships are Cyclistic members.\nCyclistic’s finance analysts have concluded that annual members are much more profitable than casual riders. Although the pricing flexibility helps Cyclistic attract more customers, Moreno believes that maximizing the number of annual members will be key to future growth. Rather than creating a marketing campaign that targets all-new customers, Moreno believes there is a very good chance to convert casual riders into members. She notes that casual riders are already aware of the Cyclistic program and have chosen Cyclistic for their mobility needs.\nMoreno has set a clear goal: Design marketing strategies aimed at converting casual riders into annual members. In order to do that, however, the marketing analyst team needs to better understand how annual members and casual riders differ, why casual riders would buy a membership, and how digital media could affect their marketing tactics. Moreno and her team are interested in analyzing the Cyclistic historical bike trip data to identify trends.\n\n\nProject deliverables\nProduce a report with the following deliverables:\n\n\nA clear statement of the business task.\nA description of all data sources used.\nDocumentation of any cleaning or manipulation of data.\nA summary of your analysis.\nSupporting visualizations and key findings.\nYour top three recommendations based on your analysis.\n\n\n\n\nAsk\nKey tasks:\n1. Identify the business task\n  The business objective is to convert occasional riders into annual members, which is crucial for driving   the company’s future growth. The primary purpose of this analysis is to identify trends and differences   in riding behavior between casual riders and annual members. The insights derived from this analysis   will serve as a foundation for informing the company’s marketing strategies and efforts aimed at   converting casual riders into loyal annual members.\n2. Key stakeholders:\n  Cyclistic executive team, Director of Marketing (Lily Moreno), Marketing Analytics team\nStatement of the business task\nUnderstand how Cyclistic casual riders and annual members ride differ by analyzing the Cyclistic historical bike trip data to identify trends.\n\n\nPrepare\nKey tasks:\n1. Download data and store it appropriately.\nThe previous 12 months of Cyclistic trip data is available for download here. They are made available by Motivate International Inc., under license. 12 CSV files have been downloaded and saved in the folder C:\\Users\\Joon\\git\\albert-joonyoung-park.github.io\\data.\n2. Identify how it’s organized\nThe data files are in csv format, and organized into individual month for the past 12 month period.\n3. Sort and filter the data.\nSpreadsheet was used to perform for initial inspection on some data files, and found some issues that require data cleaning and transformation.\n\nManyu columns contain some missing values - started_at, ended_at, start_station_name, end_station_name, end_station_id, start_lat, end_lat\nride_id column contains inconsistent data types, mixture of character and number type data.\nWhen “ride length was calculated based on” based on started_at, ended_at, some results showed unrealistic large or small numbers, exceeding over 24 hour, 0 or a few minutes of trips.\nAll files have the same column names and same number of columns.\nEach data file contains large amount of rows ranging 180,000 - 800,000+ rows.\n\n4. Determine the credibility of the data.\nROCCC measurement was applied to check the credibility of the data.\n\nReliable (R): The collection of dataset provide the full 12-month bike trip data. It is partial or biased.\nOriginal (O): The dataset is first party and public data, directly supplied by the the company - Cyclistic.\nComprehensive (C): The dataset contains enough information to answer the business task in question.\nCurrent (C): The dataset is current, proviing the current full-year bike trip data.\nCited (C): The dataset is made available as public data by the company and municipality, and is clearly cited online with license information.\n\nA description of all data sources used\n12 bike trip csv data files for the period from May 2022 to April 2023 were used as data source. The data source was available as first party public data by the company Motivate International Inc. The original files are named below.\n\n\n\nFile name\n\n\n\n\n202205-divvy-tripdata.csv\n\n\n202206-divvy-tripdata.csv\n\n\n202207-divvy-tripdata.csv\n\n\n202208-divvy-tripdata.csv\n\n\n202209-divvy-publictripdata.csv\n\n\n202210-divvy-tripdata.csv\n\n\n202211-divvy-tripdata.csv\n\n\n202212-divvy-tripdata.csv\n\n\n202301-divvy-tripdata.csv\n\n\n202302-divvy-tripdata.csv\n\n\n202303-divvy-tripdata.csv\n\n\n202304-divvy-tripdata.csv\n\n\n\n\n\nProcess\nKey tasks\n1. Check the data for errors.\n2. Choose your tools.\n3. Transform the data so you can work with it effectively.\n4. Document the cleaning process.\nDeliverable\nR was chosen for data inspection, cleaning and manipulation. The following code blocks are steps of data cleaning and manipulations for future analysis.\n\n# Set up working directory\nsetwd(\"C:/Users/Joon/git/albert-joonyoung-park.github.io/projects\")\n\n# Load required libraries to use\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(skimr)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(scales)\nlibrary(leaflet)\nlibrary(kableExtra)\n\n\n# List all the CSV data file names to be imported.\nfile_names &lt;- list.files(path = \"../data/\",\n                         pattern = \"*.csv\", full.names = FALSE,\n                         recursive = FALSE)\n# file_names\n\n# Import csv data files one at time and clean, transform the data\ntotal_num_rows &lt;- 0\ntotal_num_rows_dropped &lt;- 0\ntotal_num_rows_duplicated &lt;- 0\n\nfor (name in file_names) {\n  \n  # Import a csv file\n  data &lt;- read_csv(paste(\"../data/\", name, sep = \"\"))\n  num_rows &lt;- nrow(data)\n  #print(paste(num_rows, \"rows imported from\", name)) # number of rows imported\n  total_num_rows &lt;- total_num_rows + num_rows\n  \n  # Cleaning - drop rows with missing values - NA\n  data_na_dropped &lt;- drop_na(data)\n  num_rows_dropped &lt;- num_rows - nrow(data_na_dropped)\n  #print(paste(num_rows_dropped,\"rows with missing value dropped from\",name))\n  total_num_rows_dropped &lt;- total_num_rows_dropped + num_rows_dropped\n  \n  # Cleaning - remove duplicates\n  data_unique_na_dropped &lt;- distinct(data_na_dropped)\n  num_rows_duplicated &lt;- nrow(data_unique_na_dropped) - nrow(data_na_dropped)\n  total_num_rows_duplicated &lt;- total_num_rows_duplicated + num_rows_duplicated\n  \n  # Transformation:\n  # add columns to increase aggregation levels for analysis.\n  # lmit ride_length values\n  trip_month_data_clean &lt;- \n    data_unique_na_dropped |&gt; \n      mutate(\n        start_date = as.Date(started_at),\n        start_hour = format(started_at, \"%H\"),\n        start_month = format(start_date, \"%m\"),\n        start_day = format(start_date, \"%d\"),\n        start_year = format(start_date, \"%Y\"),\n        #start_weekday = format(start_date, \"%A\"),\n        start_weekday = wday(start_date, week_start = 7),\n        ride_length = difftime(ended_at, started_at, units = \"secs\"),\n        .after = started_at\n      ) |&gt; \n      filter(ride_length &gt; 0 & ride_length &lt;= 3600) # limit ride_length\n\n  # Save cleaned data files as a CSV file\n  write_csv(trip_month_data_clean, \n            paste(\"../data/cleaned_datasets/\", name, sep = \"\"))\n}\n\n# print some row number changes and structure of cleaned data being saved\ntotal_num_rows # 5859061 rows\n\n[1] 5859061\n\ntotal_num_rows_dropped # 1325062 rows\n\n[1] 1325062\n\ntotal_num_rows_duplicated # 0 row\n\n[1] 0\n\nglimpse(trip_month_data_clean)\n\nRows: 315,757\nColumns: 20\n$ ride_id            &lt;chr&gt; \"5B6500E1E58655C0\", \"AA65D25D69AF771F\", \"079FB2C196…\n$ rideable_type      &lt;chr&gt; \"classic_bike\", \"classic_bike\", \"electric_bike\", \"c…\n$ started_at         &lt;dttm&gt; 2023-04-10 17:34:35, 2023-04-12 12:29:46, 2023-04-…\n$ start_date         &lt;date&gt; 2023-04-10, 2023-04-12, 2023-04-13, 2023-04-29, 20…\n$ start_hour         &lt;chr&gt; \"17\", \"12\", \"17\", \"20\", \"17\", \"22\", \"21\", \"11\", \"11…\n$ start_month        &lt;chr&gt; \"04\", \"04\", \"04\", \"04\", \"04\", \"04\", \"04\", \"04\", \"04…\n$ start_day          &lt;chr&gt; \"10\", \"12\", \"13\", \"29\", \"20\", \"14\", \"07\", \"05\", \"05…\n$ start_year         &lt;chr&gt; \"2023\", \"2023\", \"2023\", \"2023\", \"2023\", \"2023\", \"20…\n$ start_weekday      &lt;dbl&gt; 2, 4, 5, 7, 5, 6, 6, 4, 4, 2, 7, 3, 1, 4, 3, 1, 2, …\n$ ride_length        &lt;drtn&gt; 1681 secs, 1454 secs, 94 secs, 3 secs, 1307 secs, …\n$ ended_at           &lt;dttm&gt; 2023-04-10 18:02:36, 2023-04-12 12:54:00, 2023-04-…\n$ start_station_name &lt;chr&gt; \"Avenue O & 134th St\", \"Cottage Grove Ave & 51st St…\n$ start_station_id   &lt;chr&gt; \"20214\", \"TA1309000067\", \"TA1306000002\", \"TA1309000…\n$ end_station_name   &lt;chr&gt; \"Avenue O & 134th St\", \"Cottage Grove Ave & 51st St…\n$ end_station_id     &lt;chr&gt; \"20214\", \"TA1309000067\", \"TA1306000002\", \"TA1309000…\n$ start_lat          &lt;dbl&gt; 41.65187, 41.80304, 41.86243, 41.80304, 41.90303, 4…\n$ start_lng          &lt;dbl&gt; -87.53967, -87.60662, -87.65115, -87.60662, -87.697…\n$ end_lat            &lt;dbl&gt; 41.65187, 41.80304, 41.86238, 41.80304, 41.92269, 4…\n$ end_lng            &lt;dbl&gt; -87.53967, -87.60662, -87.65106, -87.60662, -87.697…\n$ member_casual      &lt;chr&gt; \"member\", \"member\", \"member\", \"member\", \"casual\", \"…\n\n\n\n\nAnalyze\nKey tasks\n1. Aggregate your data so it’s useful and accessible.\n2. Organize and format your data.\n3. Perform calculations.\n4. Identify trends and relationships.\nDeliverable\nA summary of your analysis\n\n#----------------------------------------------------------------------------\n# Aggregate the cleaned dataset into a single data frame and inspect further\n#----------------------------------------------------------------------------\n\n# Get all the cleaned data file names for aggregation\nfile_names &lt;- list.files(path = \"../data/cleaned_datasets/\",\n                         pattern = \"*.csv\", full.names = FALSE,\n                         recursive = FALSE)\n\n# Import the first monthly cleaned csv file, so it constructs the data frame\n# for full year aggregation\nfull_year_trips &lt;- read_csv(paste(\"../data/cleaned_datasets/\", file_names[1], sep = \"\"))\n\n# Aggregate the remainig csv files, starting from the second\nfor(name in file_names[2:length(file_names)]) {\n  # Read csv file\n  trip_month_data_clean &lt;- read_csv(paste(\"../data/cleaned_datasets/\", \n                                          name, sep = \"\"))\n  \n  # Aggregate the monthly data\n  full_year_trips &lt;- rbind(full_year_trips, trip_month_data_clean)\n  \n  # Drop duplicates\n  full_year_trips &lt;- drop_na(full_year_trips)\n  \n  # Save monthly trip data into a aggregated csv file\n  write_csv(trip_month_data_clean, \"../data/analyzed_datasets/full_year_trips.csv\",\n            append = TRUE)\n}\n\n# Check the overview of the aggregated dataset\n# skim(full_year_trips) # 4393697\n\n\n#----------------------------------------------------------------------------\n# Analyze the aggregated data and create summary to find trends\n# Use question, data summary, visualization format\n# Save each summary\n#----------------------------------------------------------------------------\n\n# !. Basic descriptive analysis on ride length per member and casual groups.\n\n# Total ride frequency and percentage per member and casual group\ntotal_ride = nrow(full_year_trips)\nride_frequency_membership &lt;- \n  full_year_trips |&gt; \n    group_by(membership = member_casual) |&gt; \n    summarize( \n      ride_frequency = n(),\n      ride_freq_pct = n() / total_ride * 100\n    ) \n\n\n# visualization of total ride frequency, percentage per member and casual group\n\np &lt;- \nride_frequency_membership |&gt; \n  ggplot(aes(x = membership, y = ride_frequency, fill = membership)) +\n  geom_col() +\n  geom_text(aes(label = comma(ride_frequency)), size = 6, vjust = -0.3) +\n  geom_text(aes(label = paste(round(ride_freq_pct, digits = 2), \"%\")), size = 6, vjust = 5.0, color = \"white\") +\n  labs(title = \"Total ride frequency by membership\",\n       x = \"Membership\", y = \"Ride Frequency (2022 - 2023)\", fill = \"Membership\" ) + scale_y_continuous(labels = comma)\n\n# Save the summary data\nwrite_csv(ride_frequency_membership, \"../data/analyzed_datasets/ride_frequency_membership.csv\")\n\n# Save the plot\nplot_name &lt;- deparse(substitute(ride_frequency_membership))\nggsave(paste(\"../data/analyzed_datasets/\", plot_name, \".png\"), p, width = 6, height = 4, dpi = 300)\np\n\n\n\n# ride_frequency by quarter per member and casaul group\nride_frequency_q_membership &lt;- \n  full_year_trips |&gt; \n    group_by(qtr = paste(\"QTR\", quarter(start_date)), \n             membership = member_casual) |&gt; \n    summarize( \n      ride_frequency = n()\n    )\n\n# Save the summary data\nwrite_csv(ride_frequency_q_membership, \n          \"../data/analyzed_datasets/ride_frequency_q_membership.csv\")  \n              \n\n# mean, median, max and min ride length per member and casual groups.\nride_length_membership &lt;- \n  full_year_trips |&gt; \n    group_by(membership = member_casual) |&gt; \n    summarize(\n      mean = round(mean(ride_length / 60)),\n      median = round(median(ride_length / 60)),\n      max = round(max(ride_length / 60)),\n      min = round(min(ride_length / 60))\n    )\n\nride_length_membership &lt;- \n  ride_length_membership |&gt; \n    pivot_longer(cols = c(mean, median, max, min),\n               names_to = \"statistic\",\n               values_to = \"ride_length\")\n\np &lt;- \nride_length_membership |&gt;\n    ggplot(aes(x = statistic, y = ride_length, fill = membership)) + \n    geom_col(position = \"dodge2\") +\n    geom_label(\n      aes(label = ride_length),\n      size = 4,\n      color = \"white\",\n      position = position_dodge(width = 0.9), vjust = 0.2\n    ) +\n    labs(title = \"Ride length stats. by membership\", size = 14) +\n    labs(x = \"Basic statistic\", y = \"Ride length (mins.)\", fill = \"Membership\") \n\n# Save the summary data\nwrite_csv(ride_length_membership, \n          \"../data/analyzed_datasets/ride_length_membership.csv\")\n\n# Save the plot\nplot_name &lt;- deparse(substitute(ride_length_membership))\nggsave(paste(\"../data/analyzed_datasets/\", plot_name, \".png\"), p, width = 6, height = 4, dpi = 300)\n\np\n\n\n\n\n\n# 2. Average ride length of day of week per casual and member group\nride_length_weekday_avg &lt;- \n  full_year_trips |&gt; \n    group_by(start_weekday, member_casual) |&gt; \n    summarize(avg_ride_length = round(mean(ride_length) / 60)) |&gt; \n    arrange(start_weekday) |&gt;\n    mutate(start_weekday = recode(start_weekday, \n                                  \"1\" = \"Sunday\", \n                                  \"2\" = \"Monday\", \n                                  \"3\" = \"Tuesday\", \n                                  \"4\" = \"Wednesday\", \n                                  \"5\" = \"Thursday\", \n                                  \"6\" = \"Friday\", \n                                  \"7\" = \"Saturday\")\n           )\nride_length_weekday_avg\n\n# A tibble: 14 × 3\n# Groups:   start_weekday [7]\n   start_weekday member_casual avg_ride_length\n   &lt;chr&gt;         &lt;chr&gt;                   &lt;dbl&gt;\n 1 Sunday        casual                     18\n 2 Sunday        member                     13\n 3 Monday        casual                     16\n 4 Monday        member                     11\n 5 Tuesday       casual                     15\n 6 Tuesday       member                     11\n 7 Wednesday     casual                     15\n 8 Wednesday     member                     11\n 9 Thursday      casual                     15\n10 Thursday      member                     11\n11 Friday        casual                     16\n12 Friday        member                     11\n13 Saturday      casual                     18\n14 Saturday      member                     13\n\np &lt;- \nride_length_weekday_avg |&gt; \nggplot() +\n  geom_col(\n    aes(x = factor(start_weekday, levels=c(\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\")), \n        y = avg_ride_length, \n        fill = member_casual),\n    position = \"dodge\"\n  ) +\n  labs(title = \"Average ride length by weekday\", size = 14) +\n  labs(x = \"Weekday\", y = \"Ride length (mins.)\", fill = \"Membership\")\n\n\n# Save the summary data\nwrite_csv(ride_length_weekday_avg, \n          \"../data/analyzed_datasets/ride_length_weekday_avg.csv\")\n\n# Save the plot\nplot_name &lt;- deparse(substitute(ride_length_weekday_avg))\nggsave(paste(\"../data/analyzed_datasets/\", plot_name, \".png\"), p, width = 6, height = 4, dpi = 300)\np\n\n\n\n\n\n# 3. Ride count for day of week per member vs casual group.\n\nride_count_weekday &lt;- \n  full_year_trips |&gt; \n    mutate(weekday = wday(started_at, label = TRUE)) |&gt; \n    group_by(member_casual, weekday) |&gt; \n    summarise(\n      number_of_rides = n(),\n      avg_ride_length = as.integer(mean(ride_length)/60)\n    ) |&gt; \n    arrange(member_casual, weekday)\n\nride_count_weekday\n\n# A tibble: 14 × 4\n# Groups:   member_casual [2]\n   member_casual weekday number_of_rides avg_ride_length\n   &lt;chr&gt;         &lt;ord&gt;             &lt;int&gt;           &lt;int&gt;\n 1 casual        Sun              274808              17\n 2 casual        Mon              194524              16\n 3 casual        Tue              192448              14\n 4 casual        Wed              201808              14\n 5 casual        Thu              225061              14\n 6 casual        Fri              245557              15\n 7 casual        Sat              332954              17\n 8 member        Sun              307754              12\n 9 member        Mon              383896              11\n10 member        Tue              431802              11\n11 member        Wed              438440              11\n12 member        Thu              437776              11\n13 member        Fri              383060              11\n14 member        Sat              343809              12\n\n# Visualize the number of rides by rider type\n\np &lt;- \nride_count_weekday |&gt; \n  ggplot(aes(x = weekday, y = number_of_rides, fill = member_casual)) +\n    geom_col(position = \"dodge\") +\n    labs(title = \"Ridership by User Type\", size = 14) +\n    labs(x = \"Weekday\", y = \"Number of rides\", fill = \"User type\") +\n    scale_y_continuous(labels = comma)\n\n# Save the summary data\nwrite_csv(ride_count_weekday, \n          \"../data/analyzed_datasets/ride_count_weekday.csv\")\n\n# Save the plot\nplot_name &lt;- deparse(substitute(ride_count_weekday))\nggsave(paste(\"../data/analyzed_datasets/\", plot_name, \".png\"), p, width = 6, height = 4, dpi = 300)\np\n\n\n\n\n\n# 4. Rideable type frequencies for day of week per member vs casual group.\n\ndfs_rideable_type_member_casual &lt;- \n  full_year_trips |&gt; \n    group_by(member_casual, rideable_type) |&gt; \n    summarize(ride_count = n()) |&gt; \n    arrange(rideable_type, member_casual, ride_count)\n\ndfs_rideable_type_member_casual\n\n# A tibble: 5 × 3\n# Groups:   member_casual [2]\n  member_casual rideable_type ride_count\n  &lt;chr&gt;         &lt;chr&gt;              &lt;int&gt;\n1 casual        classic_bike      824392\n2 member        classic_bike     1739554\n3 casual        docked_bike       131036\n4 casual        electric_bike     711732\n5 member        electric_bike     986983\n\np &lt;- \ndfs_rideable_type_member_casual |&gt; \n  ggplot(aes(x = rideable_type, y = ride_count, fill = member_casual )) +\n    geom_bar(stat = \"identity\") +\n    geom_text(\n      aes(label = comma(ride_count)),\n      size = 3.5,\n      position = position_stack(vjust = 0.5),\n      colour = \"white\"\n    ) +\n    scale_y_continuous(labels = comma) +\n    labs(title = \"Ride frequency by rideable type\", size = 16) +\n    labs(subtitle = \"Period: 12 months (May 2022 - April 2023)\") +\n    labs(x = \"Rideable type\", y = \"Frequency\", fill = \"Membership\")\n\n# Save the summary data\nwrite_csv(dfs_rideable_type_member_casual, \n          \"../data/analyzed_datasets/dfs_rideable_type_member_casual.csv\")\n\n# Save the plot\nplot_name &lt;- deparse(substitute(ride_count_weekday))\nggsave(paste(\"../data/analyzed_datasets/\", plot_name, \".png\"), p, width = 6, height = 4, dpi = 300)\np\n\n\n\n\n\n# 5. Display a map marking the start staion that are frequently used by member or casual riders.\n\n# Geographical mapping of ridership by membership, using leaflet\n# Prepare data in a smaller set for plotting - limit to ride frequency over 1200\n\ndfs_ride_start_loc &lt;- \n  full_year_trips |&gt; \n    select(start_station_name, start_lat, start_lng, member_casual) |&gt; \n    group_by(start_station_name, start_lat, start_lng, member_casual) |&gt; \n    summarize(\n      ride_frequency = n()\n      ) |&gt; \n    filter(ride_frequency &gt;= 1200) # limit the ride_frequency &gt;= 1200\n\ndfs_ride_start_loc\n\n# A tibble: 614 × 5\n# Groups:   start_station_name, start_lat, start_lng [377]\n   start_station_name         start_lat start_lng member_casual ride_frequency\n   &lt;chr&gt;                          &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                  &lt;int&gt;\n 1 900 W Harrison St               41.9     -87.6 casual                  1728\n 2 900 W Harrison St               41.9     -87.6 member                  5506\n 3 Aberdeen St & Jackson Blvd      41.9     -87.7 casual                  1520\n 4 Aberdeen St & Jackson Blvd      41.9     -87.7 member                  5750\n 5 Aberdeen St & Monroe St         41.9     -87.7 casual                  1581\n 6 Aberdeen St & Monroe St         41.9     -87.7 member                  4349\n 7 Aberdeen St & Randolph St       41.9     -87.7 casual                  1822\n 8 Aberdeen St & Randolph St       41.9     -87.7 member                  3850\n 9 Ada St & Washington Blvd        41.9     -87.7 casual                  1322\n10 Ada St & Washington Blvd        41.9     -87.7 member                  3010\n# ℹ 604 more rows\n\n# Create a leaflet map centered on Chicago with map view\n# Display both member and casual ridership information\n\nleaflet(options = leafletOptions(zoomControl = TRUE)) |&gt; \n  setView(lng = -87.6298, lat = 41.8781, zoom = 13) |&gt; \n  addTiles() |&gt; \n   addCircleMarkers(\n     data = dfs_ride_start_loc,\n     lat = ~start_lat,\n     lng = ~start_lng,\n     radius = ~10,\n     color = ~ifelse(member_casual == \"member\", \"blue\", \"red\"),\n     popup = ~paste(start_station_name, \" | \", member_casual, \" | \", ride_frequency),\n     stroke = FALSE,\n     fillOpacity = 0.0001 * dfs_ride_start_loc$ride_frequency\n  )  \n\n\n\n\n\n\n# Create a leaflet map centered on Chicago with map view\n# Display Casual riders information only\n\ndfs_ride_start_loc_casual &lt;- \n  dfs_ride_start_loc |&gt; \n    filter(member_casual == \"casual\")\n\nleaflet(options = leafletOptions(zoomControl = TRUE)) |&gt; \n  setView(lng = -87.6298, lat = 41.8781, zoom = 13) |&gt; \n  addTiles() |&gt; \n   addCircleMarkers(\n     data = dfs_ride_start_loc_casual,\n     lat = ~start_lat,\n     lng = ~start_lng,\n     radius = ~10,\n     color = ~\"red\",\n     popup = ~paste(start_station_name, \" | \", member_casual, \" | \", ride_frequency),\n     stroke = FALSE,\n     fillOpacity = 0.0001 * dfs_ride_start_loc$ride_frequency\n  )  \n\n\n\n\n\n\n# Create a leaflet map centered on Chicago with map view\n# Display Member ridership information only\n\ndfs_ride_start_loc_member &lt;- \n  dfs_ride_start_loc |&gt; \n    filter(member_casual == \"member\")\n\nleaflet(options = leafletOptions(zoomControl = TRUE)) |&gt; \n  setView(lng = -87.6298, lat = 41.8781, zoom = 13) |&gt; \n  addTiles() |&gt; \n   addCircleMarkers(\n     data = dfs_ride_start_loc_member,\n     lat = ~start_lat,\n     lng = ~start_lng,\n     radius = ~10,\n     color = ~\"blue\",\n     popup = ~paste(start_station_name, \" | \", member_casual, \" | \", ride_frequency),\n     stroke = FALSE,\n     fillOpacity = 0.0001 * dfs_ride_start_loc$ride_frequency\n  )  \n\n\n\n\n\n\n# 6. What stations are most frequently used by casual riders in the past 12 months?\n\n# Retrieve frequent station information used by casual riders in the past 12 months\ndfs_ride_start_loc_casual &lt;- \n  full_year_trips |&gt; \n    filter(member_casual == \"casual\") |&gt; \n    group_by(start_station_id, start_station_name, member_casual) |&gt; \n    summarize(\n      ride_frequency = n(),\n      .groups = \"drop\" # need to set \"drop\" option to assign ranking properly later\n      )\n\ndfs_ride_start_loc_casual &lt;- \n  dfs_ride_start_loc_casual |&gt; \n    arrange(desc(ride_frequency)) |&gt; \n    mutate(rank = rank(-ride_frequency, ties.method = 'min')) |&gt; \n    select(rank, start_station_id, start_station_name, ride_frequency)\n\ndfs_ride_start_loc_casual_ranked &lt;- \n  dfs_ride_start_loc_casual |&gt; \n    rename(\n      \"rank\" = \"rank\", \n      \"station_id\" = \"start_station_id\",\n      \"station_name\" = \"start_station_name\",\n      \"ride_count\" = \"ride_frequency\"\n    )\n\n# List top 20 stations\n\ndfs_ride_start_loc_casual_ranked_20 &lt;- dfs_ride_start_loc_casual_ranked[1:20,]\n\n# Set ordering\ndfs_ride_start_loc_casual_ranked_20$station_name &lt;- factor(dfs_ride_start_loc_casual_ranked_20$station_name, levels = dfs_ride_start_loc_casual_ranked_20$station_name[order(dfs_ride_start_loc_casual_ranked_20$rank, decreasing = TRUE)])\n\np &lt;- \ndfs_ride_start_loc_casual_ranked_20 |&gt; \n  ggplot(aes(x = ride_count, y = station_name)) +\n    geom_bar(stat = \"identity\") +\n    labs(title = \"Top 20 stations by CASUAL riders\", size = 14) +\n    labs(x = \"Ride frequency\", y = \"Station name\") +\n    scale_x_continuous(labels = comma)\n\n# Save the summary data\nwrite_csv(dfs_ride_start_loc_casual_ranked_20, \n          \"../data/analyzed_datasets/dfs_ride_start_loc_casual_ranked_20.csv\")\n\n# Save the plot\nplot_name &lt;- deparse(substitute(dfs_ride_start_loc_casual_ranked_20))\nggsave(paste(\"../data/analyzed_datasets/\", plot_name, \".png\"), p, width = 6, height = 4, dpi = 300)\np\n\n\n\n\n\n# Create a styled table with proper number format\n\ndfs_ride_start_loc_casual_ranked_20$ride_count &lt;- format(dfs_ride_start_loc_casual_ranked_20$ride_count, big.mark = \",\")\n\nstyled_table &lt;- \n  kable(dfs_ride_start_loc_casual_ranked_20, format = \"html\", align = \"c\")  |&gt; \n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\nstyled_table\n\n\n\n\nrank\nstation_id\nstation_name\nride_count\n\n\n\n\n1\n13022\nStreeter Dr & Grand Ave\n46,750\n\n\n2\n13300\nDuSable Lake Shore Dr & Monroe St\n26,117\n\n\n3\n13042\nMichigan Ave & Oak St\n20,291\n\n\n4\nLF-005\nDuSable Lake Shore Dr & North Blvd\n20,202\n\n\n5\n13008\nMillennium Park\n19,517\n\n\n6\n15544\nShedd Aquarium\n17,959\n\n\n7\nTA1308000001\nTheater on the Lake\n15,606\n\n\n8\nTA1308000050\nWells St & Concord Ln\n14,555\n\n\n9\n13146\nClark St & Armitage Ave\n11,879\n\n\n10\nTA1307000039\nClark St & Elm St\n11,665\n\n\n11\n13179\nClark St & Lincoln Ave\n11,580\n\n\n12\nKA1503000064\nDusable Harbor\n11,555\n\n\n13\nSL-005\nIndiana Ave & Roosevelt Rd\n11,319\n\n\n14\nKA1504000135\nWells St & Elm St\n11,121\n\n\n15\n632\nClark St & Newport St\n10,816\n\n\n16\n13137\nBroadway & Barry Ave\n10,458\n\n\n17\nTA1307000134\nWilton Ave & Belmont Ave\n10,336\n\n\n18\nTA1308000012\nMontrose Harbor\n10,129\n\n\n19\n13431\nAdler Planetarium\n9,890\n\n\n20\nTA1307000117\nWabash Ave & Grand Ave\n9,716\n\n\n\n\n\n\n\n\n\nShare\nThe following data visualizations are shared on Tableau Public, accessible through this link.\n\n\n\nRide Frequency: Past 12 mo.\n\n\n\n\n\nBasic Ride Length Stats.\n\n\n\n\n\nAverage Ride Length per Day of the Week\n\n\n\n\n\n\n\n\n\n\nRide Frequency per Yearly Quarter\n\n\n\n\n\nTop 20 Start Stations by Casual Riders\n\n\n\n\nAct"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "The Cyclistic Bike-share Analysis Case Study\n\n\n\n\n\n\n\n\n\nFebruary 5, 2023\n\n\nAlbert Joonyoung Park\n\n\n21 min\n\n\n\n\n\n\nNo matching items"
  }
]